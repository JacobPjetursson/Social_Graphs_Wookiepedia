{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing (Scraping and fixing data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib2\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_characters():\n",
    "    baseurl = \"https://en.wikipedia.org/w/api.php?\"\n",
    "    action = \"action=query\"\n",
    "    title = \"titles=List_of_Star_Wars_characters\"\n",
    "    content = \"prop=revisions\"\n",
    "    rvprop =\"rvprop=timestamp|content\"\n",
    "    dataformat = \"format=json\"\n",
    "    rvdir = \"rvdir=older\" #sort revisions from newest to oldest\n",
    "    end = \"rvend=2000-01-03T00:00:00Z\" #start of my time period\n",
    "    start = \"rvstart=2019-01-03T00:00:00Z\" #end of my time period\n",
    "    limit = \"rvlimit=1\" #consider only the first revision\n",
    "\n",
    "    query = \"%s%s&%s&%s&%s&%s&%s&%s&%s&%s\" % \\\n",
    "    (baseurl, action, title, content, rvprop, dataformat, rvdir, end, start, limit)\n",
    "    response = urllib2.urlopen(query)\n",
    "    wikisource = response.read()\n",
    "    wikijson = json.loads(wikisource)\n",
    "    wikiid = wikijson[\"query\"][\"pages\"].keys()[0]\n",
    "    text = wikijson[\"query\"][\"pages\"][wikiid][\"revisions\"][-1][\"*\"]\n",
    "    # All characters on this page match the regex below\n",
    "    regex = \"\\{\\{visible anchor\\|(.*?)\\}\\}\"\n",
    "    chars = re.findall(regex,text)\n",
    "    characters = []\n",
    "    for c in chars :\n",
    "        for s in c.split(\"|\") :\n",
    "            st = ((s.replace(\"[\", \"\")).replace(\"]\",\"\")).replace(\" \",\"_\")\n",
    "            # some prefix/suffix fixes\n",
    "            if (st.startswith(\"Admiral_\")):\n",
    "                st = st[8:]\n",
    "            st = st.replace(\"_(Star_Wars)\", \"\")\n",
    "            characters.append(st)   \n",
    "    # Anakin skywalker and Darth Sidious is a special case\n",
    "    characters.append(\"Anakin_Skywalker\")\n",
    "    characters.append(\"Darth_Sidious\")\n",
    "    return set(characters)\n",
    "\n",
    "\n",
    "def fetch_wiki_article(title_):\n",
    "    baseurl = \"http://starwars.wikia.com/api.php?\"\n",
    "    action = \"action=query\"\n",
    "    title = \"titles=\" + title_ + \"&&redirects\" # Redirects are gods gift to man\n",
    "    title = title.encode(\"utf-8\") # This is our fix for unicode problems\n",
    "    content = \"prop=revisions\"\n",
    "    rvprop =\"rvprop=timestamp|content\"\n",
    "    dataformat = \"format=json\"\n",
    "    rvdir = \"rvdir=older\" #sort revisions from newest to oldest\n",
    "    end = \"rvend=2000-01-03T00:00:00Z\" #start of my time period\n",
    "    start = \"rvstart=2019-01-03T00:00:00Z\" #end of my time period\n",
    "    limit = \"rvlimit=1\" #consider only the first revision\n",
    "\n",
    "    query = \"%s%s&%s&%s&%s&%s&%s&%s&%s&%s\" % \\\n",
    "    (baseurl, action, title, content, rvprop, dataformat, rvdir, end, start, limit)\n",
    "    response = urllib2.urlopen(query)\n",
    "    wikisource = response.read()\n",
    "    wikijson = json.loads(wikisource)\n",
    "    wikiid = wikijson[\"query\"][\"pages\"].keys()[0]\n",
    "    title = wikijson[\"query\"][\"pages\"][wikiid][\"title\"]\n",
    "    text = None\n",
    "    # Below is equivalent to check if page exists\n",
    "    if wikiid != \"-1\" :\n",
    "        text = wikijson[\"query\"][\"pages\"][wikiid][\"revisions\"][-1][\"*\"]\n",
    "    # Legends is the comic books of starwars, which is sometimes redirected to.\n",
    "    # we don't want the characters from that\n",
    "    if title.endswith(\"/Legends\"): \n",
    "        title = title.replace(\"/Legends\", \"\").replace(\" \", \"_\")\n",
    "        return fetch_wiki_article(title) \n",
    "    return wikiid, text, title\n",
    "\n",
    "def addToDict(character):\n",
    "    wiki_id, text, wiki_title = fetch_wiki_article(character)\n",
    "    if wiki_id == \"-1\":\n",
    "        return False\n",
    "    if wiki_id not in wiki_ids:\n",
    "        wiki_ids.add(wiki_id)\n",
    "        # Add the wookiepedia title as key and not the character name from wiki\n",
    "        charDict[wiki_title] = text\n",
    "    return True\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "charDict = {}\n",
    "characters = fetch_characters()\n",
    "wiki_ids = set()\n",
    "leftovers = []\n",
    "for c in characters:\n",
    "    if not addToDict(c):\n",
    "        leftovers.append(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding missing characters, deleting some that shouldn't be there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIST OF CHARACTERS NOT FOUND. HAS LENGTH: 18\n",
      "[u'Inquisitors', u'Tallissan_\"Tallie\"_Lintra', u'Aiolin_and_Morit_Astarte', u'Commander_Cody_(CC-2224)', u'Garazeb_\"Zeb\"_Orrelios', u'Lieutenant_Kaydel_Ko_Connix', u'Count_Dooku<br>{{small', u'Pagetti_Rook_(\"Weequay\")', u'Orrimaarko_(\"Prune_Face\")', u'Has_Obbit', u'Rinnriyin_Di', u'Commander_Fil_(CC-3714)', u'Lieutenant_Connix', u'Orrimarko', u'Temmin_\"Snap\"_Wexley', u'RA-7_(\"Death_Star_droid\")', u'Breha_Antilles-Organa', u'Saelt-Marae_(\"Yak_Face\")']\n"
     ]
    }
   ],
   "source": [
    "# Cleaning up leftover characters\n",
    "\n",
    "# Try right side of all leftover characters separated by \"_\", since a lot of them starts with some stupid prefix\n",
    "fixed_leftovers = []\n",
    "for character in leftovers:\n",
    "    char = character.split(\"_\")[-1]\n",
    "    if not addToDict(char):\n",
    "        fixed_leftovers.append(character)\n",
    "\n",
    "print(\"LIST OF CHARACTERS NOT FOUND. HAS LENGTH: %s\" % len(fixed_leftovers))\n",
    "print(fixed_leftovers)\n",
    "manual_fixes = [\"Tallissan_Lintra\", \"Aiolin_Astarte\", \"Morit_Astarte\", \"CC-2224\", \n",
    "               \"Garazeb_Orrelios\", \"Kaydel_Ko_Connix\", \"Dooku\", \"Weequay\", \"Orrimaarko\", \"Rinnrivin_Di\",\n",
    "               \"CC-3714\", \"Temmin_Wexley\", \"RA-7_protocol_droid\", \"Breha_Organa\", \"Saelt-Marae\",\n",
    "                \"The_Grand_Inquisitor\", \"Kaplan_(colonel)\"]\n",
    "for character in manual_fixes:\n",
    "    addToDict(character)\n",
    "\n",
    "to_delete = [\"Hammerhead\", \"Velus\", \"Star Wars: Doctor Aphra\", \"Kaplan\", \"Hutt\", \"Bail Prestor Organa\",\n",
    "            \"Teedo\", \"Karina the Great\", \"Grand Inquisitor\", \"Fulcrum\", \"Weequay\", \"Senator Organa\", \"Tup\",\n",
    "            \"Rogue Squadron\", \"Emperor's Royal Guard\"]\n",
    "\n",
    "for char in to_delete:\n",
    "    del charDict[char]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding affiliations and goodness score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "affil_dict = {}\n",
    "affil_dict[\"Galactic Empire\"] = -1\n",
    "affil_dict[\"Galactic Republic\"] = 1\n",
    "affil_dict[\"Alliance to Restore the Republic\"] = 1\n",
    "affil_dict[\"Confederacy of Independent Systems\"] = -1\n",
    "affil_dict[\"First Order\"] = -1\n",
    "affil_dict[\"Resistance\"] = 1\n",
    "affil_dict[\"New Republic\"] = 1\n",
    "affil_dict[\"Trade Federation\"] = -1\n",
    "affil_dict[\"Sith\"] = -1\n",
    "affil_dict[\"Jedi Order\"] = 1\n",
    "affil_dict[\"Crimson Dawn\"] = -1\n",
    "affil_dict[\"Cloud-Riders\"] = 1\n",
    "\n",
    "char_affil_dict = {}\n",
    "for char, text in charDict.items():\n",
    "    affiliation_section = re.findall(\"affiliation=[\\S\\s]*?\\}\\}\\n\", text)\n",
    "    affiliations = re.findall('\\[\\[(.*?)\\]\\]', affiliation_section[0])\n",
    "    for affiliation in affiliations:\n",
    "        for affil in affiliation.split(\"|\"):\n",
    "            if affil in affil_dict:\n",
    "                if char in char_affil_dict:\n",
    "                    char_affil_dict[char].append(affil)\n",
    "                else:\n",
    "                    char_affil_dict[char] = [affil]\n",
    "\n",
    "char_goodness_dict = {}\n",
    "# Goodness score\n",
    "for char, text in charDict.items():\n",
    "    goodness = 0\n",
    "    if char in char_affil_dict:\n",
    "        affils = char_affil_dict[char]\n",
    "        for affil in affils:\n",
    "            goodness += affil_dict[affil]\n",
    "    char_goodness_dict[char] = goodness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_species_dict = {}\n",
    "remaining = []\n",
    "for char, text in charDict.items():\n",
    "    species = re.findall(\"species=\\*?\\[\\[(.*?)\\]\\]\", text)\n",
    "    robot_class = re.findall(\"class=\\*?\\[\\[(.*?)\\]\\]\", text)\n",
    "    if species:\n",
    "        species = species[0].lower()\n",
    "        if \"|\" in species:\n",
    "            species = species.split(\"|\")[1]\n",
    "            species = \"yoda's species\"\n",
    "        char_species_dict[char] = species\n",
    "    elif robot_class:\n",
    "        robot_class = robot_class[0].lower()\n",
    "        robot_class = robot_class.split(\"|\")[0]\n",
    "        char_species_dict[char] = \"robot: %s\" % robot_class\n",
    "    else:\n",
    "        remaining.append(char)\n",
    "\n",
    "# Manual corrections:\n",
    "char_species_dict[\"Maz Kanata\"] = \"humanoid\"\n",
    "char_species_dict[\"Tasu Leech\"] = \"human\"\n",
    "char_species_dict[\"Bendu\"] = \"unknown\"\n",
    "char_species_dict[\"Gallius Rax\"] = \"human\"\n",
    "char_species_dict[\"L3-37\"] = \"pilot droid\"\n",
    "char_species_dict[\"WAC-47\"] = \"pit droid\"\n",
    "char_species_dict[\"Sixth Brother\"] = \"human\"\n",
    "char_species_dict[\"Cylo\"] = \"humanoid\"\n",
    "char_species_dict[\"Jaxxon\"] = \"rabbit\"\n",
    "char_species_dict[\"Fifth Brother\"] = \"humanoid\"\n",
    "char_species_dict[\"Yaddle\"] = \"yoda's species\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving characters and their wiki pages to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('starwarscharacters.csv', 'w+') as csvfile:\n",
    "    fieldnames = ['name','wookieepedia_name', 'species', 'goodness']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for name in charDict.keys() :\n",
    "        wookieename = name.replace(\" \", \"_\")\n",
    "        newName = name.split(\"/\")[0]\n",
    "        writer.writerow({'name': newName.encode(\"utf-8\"),\n",
    "                         'wookieepedia_name': wookieename.encode(\"utf-8\"),\n",
    "                         'species' : char_species_dict[name], 'goodness' : char_goodness_dict[name]})\n",
    "\n",
    "for name, text in charDict.items():\n",
    "    fileName = name.replace(\" \", \"_\")\n",
    "    fileName = fileName.split(\"/\")[0]\n",
    "    f = open(\"./Wookiepediafiles/\" + fileName + \".txt\", \"w+\")\n",
    "    f.write(text.encode(\"utf-8\"))\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movie transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = \"\\<pre\\>((.|\\s)*?)\\<\\/pre\\>\"\n",
    "cwd = os.getcwd()\n",
    "os.chdir(cwd + \"/Scripts\")\n",
    "movietitles = [\"A-New-Hope\", \"Attack-of-the-Clones\", \"Return-of-the-Jedi\", \"Revenge-of-the-Sith\", \"The-Empire-Strikes-Back\", \"The-Force-Awakens\", \"The-Phantom-Menace\"]\n",
    "for title in movietitles :\n",
    "    response = urllib2.urlopen(\"https://www.imsdb.com/scripts/Star-Wars-\"+title+\".html\")\n",
    "    source = response.read()\n",
    "    script = re.findall(regex,source)\n",
    "    if script == [] :\n",
    "        reg = \"(STAR WARS EPISODE ((.|\\s)*?) END TITLES)\"\n",
    "        script = re.findall(reg,source)\n",
    "    script = script[0][0]\n",
    "    script = script.replace(\"<b>\", \"\")\n",
    "    script = script.replace(\"<br>\", \"\")\n",
    "    script = script.replace(\"</b>\", \"\")\n",
    "    script = script.replace(\"</br>\", \"\")\n",
    "    f = open(title + \".txt\", \"w+\")\n",
    "    f.write(unicode(script, errors='ignore'))\n",
    "    f.close()\n",
    "os.chdir(cwd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The last jedi is not in imsdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseurl = \"http://transcripts.wikia.com/api.php?\"\n",
    "action = \"action=query\"\n",
    "title = \"titles=Star_Wars_Episode_VIII:_The_Last_Jedi\"\n",
    "content = \"prop=revisions\"\n",
    "rvprop =\"rvprop=timestamp|content\"\n",
    "dataformat = \"format=json\"\n",
    "rvdir = \"rvdir=older\" #sort revisions from newest to oldest\n",
    "end = \"rvend=2000-01-03T00:00:00Z\" #start of my time period\n",
    "start = \"rvstart=2019-01-03T00:00:00Z\" #end of my time period\n",
    "limit = \"rvlimit=1\" #consider only the first revision\n",
    "query = \"%s%s&%s&%s&%s&%s&%s&%s&%s&%s\" % \\\n",
    "(baseurl, action, title, content, rvprop, dataformat, rvdir, end, start, limit)\n",
    "response = urllib2.urlopen(query)\n",
    "wikisource = response.read()\n",
    "wikijson = json.loads(wikisource)\n",
    "wikiid = wikijson[\"query\"][\"pages\"].keys()[0]\n",
    "text = wikijson[\"query\"][\"pages\"][wikiid][\"revisions\"][-1][\"*\"]\n",
    "text = text.replace(\"<p style=\\\"text-align:center;\\\">\",\"\")\n",
    "text = text.replace(\"</p>\",\"\")\n",
    "texts = text.split(\"[\")\n",
    "text = texts[0]\n",
    "os.chdir(cwd + \"/Scripts\")\n",
    "f = open(\"The-Last-Jedi.txt\", \"w+\")\n",
    "f.write(text.encode(\"utf-8\"))\n",
    "f.close()\n",
    "os.chdir(cwd)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
