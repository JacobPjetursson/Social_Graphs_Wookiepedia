{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fun stuff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib2\n",
    "import json\n",
    "import unicodedata\n",
    "import re\n",
    "import networkx as nx\n",
    "from colour import Color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_characters():\n",
    "    baseurl = \"https://en.wikipedia.org/w/api.php?\"\n",
    "    action = \"action=query\"\n",
    "    title = \"titles=List_of_Star_Wars_characters\"\n",
    "    content = \"prop=revisions\"\n",
    "    rvprop =\"rvprop=timestamp|content\"\n",
    "    dataformat = \"format=json\"\n",
    "    rvdir = \"rvdir=older\" #sort revisions from newest to oldest\n",
    "    end = \"rvend=2000-01-03T00:00:00Z\" #start of my time period\n",
    "    start = \"rvstart=2019-01-03T00:00:00Z\" #end of my time period\n",
    "    limit = \"rvlimit=1\" #consider only the first revision\n",
    "\n",
    "    query = \"%s%s&%s&%s&%s&%s&%s&%s&%s&%s\" % \\\n",
    "    (baseurl, action, title, content, rvprop, dataformat, rvdir, end, start, limit)\n",
    "    response = urllib2.urlopen(query)\n",
    "    wikisource = response.read()\n",
    "    wikijson = json.loads(wikisource)\n",
    "    wikiid = wikijson[\"query\"][\"pages\"].keys()[0]\n",
    "    text = wikijson[\"query\"][\"pages\"][wikiid][\"revisions\"][-1][\"*\"]\n",
    "    # All characters on this page match the regex below\n",
    "    regex = \"\\{\\{visible anchor\\|(.*?)\\}\\}\"\n",
    "    chars = re.findall(regex,text)\n",
    "    characters = []\n",
    "    for c in chars :\n",
    "        for s in c.split(\"|\") :\n",
    "            st = ((s.replace(\"[\", \"\")).replace(\"]\",\"\")).replace(\" \",\"_\")\n",
    "            # prefix/suffix fixes\n",
    "            if (st.startswith(\"Admiral_\")):\n",
    "                st = st[8:]\n",
    "            st = st.replace(\"_(Star_Wars)\", \"\")\n",
    "            #char = unicodedata.normalize('NFKD', st).encode('ascii','ignore')\n",
    "            characters.append(st)   \n",
    "    # Anakin skywalker is a special case\n",
    "    characters.append(\"Anakin_Skywalker\")\n",
    "    return set(characters)\n",
    "\n",
    "\n",
    "def fetch_wiki_article(title_):\n",
    "    baseurl = \"http://starwars.wikia.com/api.php?\"\n",
    "    action = \"action=query\"\n",
    "    title = \"titles=\" + title_ + \"&&redirects\" # Redirects are gods gift to man\n",
    "    title = title.encode(\"utf-8\") # This is our fix for unicode problems\n",
    "    content = \"prop=revisions\"\n",
    "    rvprop =\"rvprop=timestamp|content\"\n",
    "    dataformat = \"format=json\"\n",
    "    rvdir = \"rvdir=older\" #sort revisions from newest to oldest\n",
    "    end = \"rvend=2000-01-03T00:00:00Z\" #start of my time period\n",
    "    start = \"rvstart=2019-01-03T00:00:00Z\" #end of my time period\n",
    "    limit = \"rvlimit=1\" #consider only the first revision\n",
    "\n",
    "    query = \"%s%s&%s&%s&%s&%s&%s&%s&%s&%s\" % \\\n",
    "    (baseurl, action, title, content, rvprop, dataformat, rvdir, end, start, limit)\n",
    "    response = urllib2.urlopen(query)\n",
    "    wikisource = response.read()\n",
    "    wikijson = json.loads(wikisource)\n",
    "    wikiid = wikijson[\"query\"][\"pages\"].keys()[0]\n",
    "    title = wikijson[\"query\"][\"pages\"][wikiid][\"title\"]\n",
    "    text = None\n",
    "    # Below is equivalent to check if page exists\n",
    "    if wikiid != \"-1\" :\n",
    "        text = wikijson[\"query\"][\"pages\"][wikiid][\"revisions\"][-1][\"*\"]\n",
    "    # Legends is the comic books of starwars, which is sometimes redirected to.\n",
    "    # we don't want the characters from that\n",
    "    if title.endswith(\"/Legends\"): \n",
    "        title = title.replace(\"/Legends\", \"\").replace(\" \", \"_\")\n",
    "        return fetch_wiki_article(title) \n",
    "    return wikiid, text, title\n",
    "\n",
    "def addToDict(character):\n",
    "    wiki_id, links, wiki_title = fetch_wiki_article(character)\n",
    "    if wiki_id == \"-1\":\n",
    "        return False\n",
    "    if wiki_id not in wiki_ids:\n",
    "        wiki_ids.add(wiki_id)\n",
    "        # Add the wookiepedia title as key and not the character name from wiki\n",
    "        charDict[wiki_title] = links\n",
    "    return True\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charDict = {}\n",
    "characters = fetch_characters()\n",
    "wiki_ids = set()\n",
    "leftovers = []\n",
    "for c in characters:\n",
    "    if not addToDict(c):\n",
    "        leftovers.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Cleaning up leftover characters\n",
    "\n",
    "# Try right side of all leftover characters separated by \"_\", since a lot of them starts with some stupid title\n",
    "fixed_leftovers = []\n",
    "for character in leftovers:\n",
    "    char = character.split(\"_\")[-1]\n",
    "    if not addToDict(char):\n",
    "        fixed_leftovers.append(character)\n",
    "\n",
    "print(\"LIST OF CHARACTERS NOT FOUND. HAS LENGTH: %s\" % len(fixed_leftovers))\n",
    "print(fixed_leftovers)\n",
    "manual_fixes = [\"Tallissan_Lintra\", \"Aiolin_Astarte\", \"Morit_Astarte\", \"CC-2224\", \n",
    "               \"Garazeb_Orrelios\", \"Kaydel_Ko_Connix\", \"Dooku\", \"Weequay\", \"Orrimaarko\", \"Rinnrivin_Di\",\n",
    "               \"CC-3714\", \"Temmin_Wexley\", \"RA-7_protocol_droid\", \"Breha_Organa\", \"Saelt-Marae\", \"Kaplan_(colonel)\"]\n",
    "for character in manual_fixes:\n",
    "    addToDict(character)\n",
    "\n",
    "# Removing wrong pages\n",
    "del charDict[\"Hammerhead\"]\n",
    "del charDict[\"Velus\"]\n",
    "del charDict[\"Star Wars: Doctor Aphra\"]\n",
    "del charDict[\"Kaplan\"]\n",
    "del charDict[\"Hutt\"]\n",
    "del charDict[\"Bail Prestor Organa\"]\n",
    "del charDict[\"Teedo\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding parties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "affil_dict = {}\n",
    "affil_dict[\"Galactic Empire\"] = -1\n",
    "affil_dict[\"Galactic Republic\"] = 1\n",
    "affil_dict[\"Alliance to Restore the Republic\"] = 1\n",
    "affil_dict[\"Confederacy of Independent Systems\"] = -1\n",
    "affil_dict[\"First Order\"] = -1\n",
    "affil_dict[\"Resistance\"] = 1\n",
    "affil_dict[\"New Republic\"] = 1\n",
    "affil_dict[\"Trade Federation\"] = -1\n",
    "affil_dict[\"Sith\"] = -1\n",
    "affil_dict[\"Jedi Order\"] = 1\n",
    "affil_dict[\"Crimson Dawn\"] = -1\n",
    "affil_dict[\"Cloud-Riders\"] = 1\n",
    "\n",
    "char_affil_dict = {}\n",
    "for char, text in charDict.items():\n",
    "    affiliation_section = re.findall(\"affiliation=[\\S\\s]*?\\}\", text)\n",
    "    if not affiliation_section:\n",
    "        print(char)\n",
    "    affiliations = re.findall('\\[\\[(.*?)\\]\\]', affiliation_section[0])\n",
    "    for affiliation in affiliations:\n",
    "        for affil in affiliation.split(\"|\"):\n",
    "            if affil in affil_dict:\n",
    "                if char in char_affil_dict:\n",
    "                    char_affil_dict[char].append(affil)\n",
    "                else:\n",
    "                    char_affil_dict[char] = [affil]\n",
    "print(char_affil_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"CHARACTERS IN DICT: (%s):\\n %s\" % (len(charDict.keys()), charDict.keys()))\n",
    "G = nx.DiGraph()\n",
    "for char, text in charDict.items():\n",
    "    # check node affilliation score\n",
    "    affil_score = 0\n",
    "    if char in char_affil_dict:\n",
    "        affils = char_affil_dict[char]\n",
    "        for affil in affils:\n",
    "            affil_score += affil_dict[affil]\n",
    "    G.add_node(char, goodness=affil_score)\n",
    "\n",
    "for char, text in charDict.items():\n",
    "    links = re.findall('\\[\\[(.*?)\\]\\]', text)\n",
    "    for link in links:\n",
    "        for l in link.split(\"|\"):\n",
    "            if l in charDict:\n",
    "                if G.has_edge(char, l):\n",
    "                    # If edge already exists, increase weight of it by 1\n",
    "                    G[char][l]['weight'] += 1.0\n",
    "                else:\n",
    "                    G.add_edge(char, l)\n",
    "                    G[char][l]['weight'] = 1\n",
    "                break\n",
    "\n",
    "print(\"Amount of nodes: %s\" % G.number_of_nodes())\n",
    "print(\"Amount of edges: %s\" % G.number_of_edges())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw network\n",
    "%matplotlib inline\n",
    "from fa2 import ForceAtlas2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "G_undir = G.to_undirected()\n",
    "\n",
    "# set up forceatlas2 parameters\n",
    "forceatlas2 = ForceAtlas2(# Behavior alternatives\n",
    "                          outboundAttractionDistribution=False,  # Dissuade hubs\n",
    "                          linLogMode=False,\n",
    "                          adjustSizes=False,\n",
    "                          edgeWeightInfluence=1.0,\n",
    "\n",
    "                          # Performance\n",
    "                          jitterTolerance=1.0,  # Tolerance\n",
    "                          barnesHutOptimize=False,\n",
    "                          barnesHutTheta=1.2,\n",
    "                          multiThreaded=False,  # NOT IMPLEMENTED\n",
    "\n",
    "                          # Tuning\n",
    "                          scalingRatio=1.0,\n",
    "                          strongGravityMode=False,\n",
    "                          gravity=60.0, #1.0,\n",
    "\n",
    "                          # Log\n",
    "                          verbose=True)\n",
    "positions = forceatlas2.forceatlas2_networkx_layout(G_undir, pos=None, iterations=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8)) \n",
    "\n",
    "sizemap_degree = []\n",
    "colormap = []\n",
    "red = Color(\"red\")\n",
    "colors = list(red.range_to(Color(\"green\"), 12))\n",
    "\n",
    "for node in G_undir:\n",
    "    sizemap_degree.append(G.degree(node, weight=\"weight\"))\n",
    "    idx = G.node[node]['goodness'] + 6\n",
    "    colormap.append(str(colors[idx])) # 6 bad\n",
    "nodelist = [node for node in G_undir.nodes]\n",
    "edgelist = [edge for edge in G_undir.edges]\n",
    "plt.title(\"Starwars network\")\n",
    "nx.draw_networkx_nodes(G_undir, positions, with_labels=False, nodelist=nodelist, node_color=colormap, edgecolors=\"black\", node_size=sizemap_degree)\n",
    "nx.draw_networkx_edges(G_undir, positions, alpha=0.2, edge_color=\"black\", width=0.5, edgelist=edgelist)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees_names = sorted (G.nodes, key=lambda x: G.degree(x))\n",
    "#print(charDict[\"Anakin Skywalker\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
