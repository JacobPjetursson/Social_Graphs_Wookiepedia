{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explainers Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Motivation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is your dataset?\n",
    "\n",
    "    Star Wars Movie Transcipts for the episodes\n",
    "    Wookipedia pages for the relevant characters\n",
    "    \n",
    "\n",
    "### Why did you choose this/these particular dataset(s)?\n",
    "\n",
    "    The transcript as they hold all the information given in the movie\n",
    "    Wookieepedia pages because they hold data and connections between the characters\n",
    "    \n",
    "### What was your goal for the end user's experience?\n",
    "\n",
    "    To give an insight to what might not be obvious in the universe and get another understanding of the universe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Dataset\n",
    " \n",
    "### Write about your choices in data cleaning and preprocessing\n",
    "\n",
    "    Used regex to get the name from the list on wikipedia. All character names was written {{visible anchor | name}}, except the one for Anakin Skywalker/Darth Vader. So we could easily write a regular expression to get these. However not all the names, was the same as the ones used on Wookiepedia, which mean we had to cut of some titles like Admiral from the Wiki name or only use the last name. This however resulted in getting to many names, as some of the last name of characters had their own Wookiedpedia pages such as (Jabba the) Hutt. When this was cleaned up manually, we ended up with the 409 characters we will use for the network analysis. These names have then for convinence been saved in a CSV file along with goodness and species. We can then easily download the wookieepedia pages for all the characters. The csv file, and character pages can be found link or downloaded using this code\n",
    "    \n",
    "    The movie transcript was found on IMSDB, we then used regex to only get the script part and file can be found link or download using the code.\n",
    "\n",
    "### Write a short section that discusses the dataset stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Tools, theory and analysis\n",
    " \n",
    "     Talk about how you've worked with text, including regular expressions, unicode, etc.\n",
    " \n",
    "     Describe which network science tools and data analysis strategies you've used, how those network science measures work, and why the tools you've chosen are right for the problem you're solving.\n",
    "     \n",
    "    How did you use the tools to understand your dataset?\n",
    "\n",
    " \n",
    " ### Explain the overall idea\n",
    " \n",
    "\n",
    " \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Analysis step 1\n",
    " \n",
    " #### Explain what you're interested in\n",
    "     \n",
    "     Interested in creating a network over the characters, to analyze connections to see who is the most important person, analyze communities to see if these follow any grouping of the actual stuff such as race, movie, alliance, family or other.\n",
    " \n",
    " #### Explain the tool\n",
    " \n",
    " #### Apply the tool\n",
    " \n",
    " #### Discuss the outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Analysis step 2\n",
    " \n",
    " #### Explain what you're interested in\n",
    " \n",
    " #### Explain the tool\n",
    " \n",
    " #### Apply the tool\n",
    " \n",
    " #### Discuss the outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Discussion \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
